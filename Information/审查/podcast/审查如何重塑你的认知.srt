1

00:00:00,103 --> 00:01,863
欢迎来到政治的逻辑。

2

00:02,303 --> 00:12,713
今天我们来深入聊一聊一本书,嗯,非常有意思的书,玛格丽特·罗伯茨的《审查：中国防火墙内的分心与转移》。

3

00:13,293 --> 00:26,203
你可能啊,平时也会有这样的疑问,就是为什么有些审查制度,比如说咱们知道的防火墙,好像看起来漏洞挺多的,信息好像不难获取啊,但它好像又挺有效的。

4

00:26,853 --> 00:28,523
这本书就是想解答这个问题。

5

00:28,873 --> 00:31,443
对,它的核心观点我觉得还挺颠覆的。

6

00:31,773 --> 00:54,303
他说很多审查的目的其实不是说要把信息彻底给你堵死,而是通过增加你拿到这个信息的麻烦程度,可能是让你多花点时间或者多费点功夫,然后呢,同时用其他一些信息来分散你的注意力,这样大部分人可能自己就绕开了,有点像给信息加了个隐形的关卡。

7

00:54,583 --> 00:56,313
没错,这个观察非常到位。

8

00:56,663 --> 00:59,573
这正是这本书我觉得它的精髓所在。

9

00:59,963 --> 01:05,333
他认为现代的审查,特别是数字时代的审查,正在变得更加精巧。

10

01:05,823 --> 01:11,593
他更侧重于管理人们的注意力,而不是以前那种简单粗暴的删除信息。

11

01:12,183 --> 01:15,853
而且,罗伯茨教授他的研究不是拍脑袋想出来的,是吧?

12

01:16,283 --> 01:32,233
他用了大量的实证数据,包括他在中国做的实验,还有全国性的调查问卷、社交媒体数据分析,甚至还有一些泄露出来的官方文件,所以他提供了一个崭新的视角,帮助我们理解信息控制是怎么回事。

13

01:32,543 --> 01:38,203
好的,那咱们今天就是想为你好好梳理一下这本书的核心论点,还有他的证据。

14

01:38,483 --> 01:53,493
咱们一起搞清楚,这个审查它到底是怎么运作的,特别是书里面重点讲的三种策略：恐惧、摩擦,还有信息泛滥,看看他们具体怎么影响到我们普通人日常接触信息的方式,咱们要好好探究一下。

15

01:53,493 --> 01:58,113
行,那首先咱们就从这个所谓的漏洞百出的审查开始说起吧。

16

01:58,633 --> 02:10,383
书里就举了例子,像防火墙,咱们知道用个VPN就能绕过去,关键词屏蔽呢,大家会用谐音字或者各种奇奇怪怪的符号,就是所谓的“火星文”来躲开。

17

02:10,953 --> 02:14,753
敏感的报道可能只是被要求放在报纸不显眼的地方。

18

02:15,223 --> 02:19,653
甚至说当年谷歌也不是完全被禁,只是访问速度特别慢。

19

02:20,313 --> 02:22,863
这听起来好像防线不是很牢固啊。

20

02:23,193 --> 02:26,113
嗯,这恰恰就是问题的关键。

21

02:26,603 --> 02:37,133
罗伯茨他认为啊,这种所谓的漏洞或者说多孔性,很多时候可能不是因为技术不行或者监管不到位,反而它本身可能就是一种策略。

22

02:37,653 --> 02:38,303
哦,策略？

23

02:38,553 --> 02:41,643
像是在人群中划了一条线。

24

02:42,283 --> 02:52,623
你看,有少数人,他们目的特别强,或者有技术,有资源也有时间,他们愿意付出额外的成本去获取那些被限制的信息。

25

02:53,243 --> 02:55,273
这部分人他们就能绕过去。嗯哼。

26

02:55,793 --> 03:06,203
但是对绝大多数人来说呢,他们可能对政治本来兴趣就没那么大,或者觉得,哎呀,没必要花那个时间那个精力去折腾。

27

03:06,623 --> 03:29,293
对这部分人来说呢,只要获取信息的成本哪怕只增加一点点,比如说网站打开慢个几秒钟,或者需要多点击一下鼠标,或者得装个什么软件,再加上政府或者其他力量制造的大量更容易获得、更吸引眼球的信息,比如娱乐八卦什么的,那么大多数人的注意力很自然的就被引到别处去了。

28

03:29,663 --> 03:33,183
嗯,这就是书里说的“分心与转移”。

29

03:33,633 --> 03:34,263
对。

30

03:34,703 --> 03:43,903
我明白了,所以关键点不在于这个信息你最终能不能找到,而在找到它有多方便,或者说有多不方便。

31

03:44,483 --> 03:52,383
只要过程稍微麻烦一点,那对于大部分没那么有动力的人来说,这个信息实际上就等于不存在了。

32

03:52,583 --> 03:53,883
对,可以这么理解。

33

03:54,233 --> 03:57,253
它的传播范围和影响力就被大大限制了。

34

03:57,393 --> 04:06,323
嗯,这个思路确实点醒了我们,审查可能在用一种更聪明或者说更隐蔽的方式在运作。

35

04:06,863 --> 04:12,143
那我们再往深挖一层,政府他为什么要费这么大劲去审查信息呢?

36

04:12,853 --> 04:21,503
当然最直接的答案肯定是为了维持权力,但是书里好像提到了更复杂的一些考量,甚至是一种两难的处境。

37

04:21,833 --> 04:24,533
对,书里管这个叫“独裁者的困境”。

38

04:25,183 --> 04:29,733
dictator's dilemma,这个概念其实也不算新,但书里把它用得很好。

39

04:30,233 --> 04:46,473
一方面呢,任何政府他肯定不希望那些负面的信息,比如说政策失误啊,官员腐败啊,或者是一些社会问题被广泛传播,因为这会损伤他的执政基础和合法性,不管是民主国家还是威权国家都有这个担忧。

40

04:46,853 --> 04:51,573
但是呢,另一方面,审查这个行为本身,它也是有成本和风险的。

41

04:52,143 --> 05:02,303
首先就是你搞那种太严厉、太公开的审查,特别是那种基于恐惧的、让人害怕的审查,很容易弄巧成拙,就是所谓的“适得其反”。

42

05:02,683 --> 05:03,893
嗯,会引起反弹。

43

05:04,363 --> 05:13,573
对,他等于公开告诉大家“我在压制信息”,这本身就可能让人觉得政府心虚,反而激起大家的好奇心和反感。

44

05:14,243 --> 05:17,893
你看那些被禁的书往往卖得更火,就是这个道理。

45

05:18,343 --> 05:35,973
其次呢,还有一个问题,如果你把所有的批评声音、不同的意见全都压下去了,那政府自己可能也就听不到社会的真实情况了,他就没法及时发现治理中存在的问题,也收集不到真实的民意反馈,这对有效治理其实是不利的。

46

05:36,443 --> 05:44,953
作者提到像中国历史上,比如大跃进时期,就因为信息渠道不畅通,导致了严重的决策失误,这算是个历史教训吧。

47

05:45,633 --> 05:48,933
就是说政府也需要信息来做决策。

48

05:49,303 --> 06:17,293
没错,最后一点,尤其在今天这个全球化、信息化的时代,信息的自由流动对经济发展太重要了,创新、市场效率、国际投资都离不开信息,如果你过度审查,特别是对互联网进行非常严格的管制,那很可能会扼杀经济活力,而经济表现往往又是很多威权政府合法性的一个重要来源,甚至是主要来源,所以你看这就很矛盾了。

49

06:17,893 --> 06:33,703
这就构成了一个两难：既想控制信息维护稳定,又怕审查带来的负面效果,包括政治上的反弹、治理上的信息缺失,还有经济上的代价。对,所以这是一个非常难把握的平衡。

50

06:34,363 --> 06:58,693
嗯,这就解释了为什么我们观察到的一些审查策略,特别是作者研究的中国案例,好像越来越倾向于采用更精巧甚至更隐蔽的方式,他们试图在控制信息和避免这些负面后果之间找到一个平衡点,或者说“走钢丝”,他们既不想引起强烈的反弹,可能也不想让自己完全变成聋子。

51

06:58,983 --> 07:06,493
是这个意思,试图达到一种既能管控住大部分信息流,又不至于付出太大代价的状态。

52

07:07,113 --> 07:17,453
好,那要理解这些精巧的策略为什么能奏效,我们还得看看信息的接收方,也就是我们普通公民,我们是怎么消费信息的。

53

07:17,993 --> 07:23,123
书里提到了一个挺重要的概念叫“理性忽视”, rationally ignorant。

54

07:23,603 --> 07:27,513
这听起来好像是说我们大家都有点懒于关心政治。

55

07:27,863 --> 07:36,993
也不能完全说是懒吧,这个概念其实是源自政治传播学和公共选择理论的,它指的是一个很普遍的现象。

56

07:37,393 --> 07:48,153
就是对大多数人来说,投入大量的时间和精力去深入的了解那些复杂的政治信息,从个人的角度来看,那个收益往往感觉不大明显,或者说很间接。

57

07:48,633 --> 07:49,273
比如说,

58

07:49,693 --> 08:06,173
比如你多花几个小时研究某个政策细节,或者了解某个国际事件的来龙去脉,这对你个人的生活或者对最终的政治结果、选举结果能产生多大的直接影响呢?对大部分人来说感觉可能微乎其微。

59

08:06,833 --> 08:12,233
但是你付出的成本,时间、精力、脑力,却是实实在在的,是吧?

60

08:12,943 --> 08:16,393
你本来用这些时间去工作、去娱乐、去陪家人。

61

08:16,683 --> 08:18,173
嗯,机会成本很高。

62

08:18,173 --> 08:28,213
对,而且现在这个时代信息实在太多了,信息过载,我们每个人的注意力都是非常有限的,是一种稀缺资源。

63

08:28,773 --> 08:51,203
所以很自然的,大家就会倾向于去关注那些获取起来更容易、更有趣,更符合自己既有观点,或者来自自己信任源的信息,甚至对于那些可能挑战自己认知,让自己感觉不舒服的信息,人们可能还会下意识的去回避,这涉及到认知失调, cognitive dissonance的理论。

64

08:51,763 --> 09:03,133
所以总结一下就是,我们对获取那些需要付出额外努力的,特别是政治类的比较严肃的信息,我们的需求弹性其实是很大的,highly elastic demand。

65

09:03,633 --> 09:12,653
这个说法很准确,就是说获取信息的成本哪怕只是增加一点点,我们消费这个信息的意愿就可能会大幅度下降。

66

09:12,933 --> 09:26,173
嗯哼,正是利用了我们普通人的这种“理性忽视”,以及对成本的这种高度敏感性,才为那些看起来漏洞百出,但实际上能增加信息获取摩擦力的审查策略提供了发挥作用的基础。

67

09:26,673 --> 09:32,293
审查者恰恰就是利用了我们这种追求便利或者说图方便的心理吧。

68

09:32,663 --> 09:39,893
明白了。这环环相扣啊,理解了政府的动机困境,又理解了我们普通人的信息消费习惯。

69

09:40,433 --> 09:53,493
那接下来我们终于可以进入这本书最核心的部分了,就是他归纳的审查发挥作用的三种核心机制：恐惧(fear), 摩擦(friction), 还有泛滥(flooding), 我们来一个一个的拆解开看看。

70

09:53,853 --> 10:08,373
好,先说第一个,恐惧,这个可能是我们最容易想到也是最传统的一种审查方式了,就是通过惩罚或者威胁要惩罚,让人们感到害怕,然后就不敢说某些话或者不敢接触某些信息。

71

10:08,613 --> 10:31,043
对,这个机制是最直接的,它包括很明确的法律法规禁止,比如说书里提到沙特禁止侮辱伊斯兰,俄罗斯有关于虚假信息的法律等等,也包括很多法外的手段,比如对异议者、活动人士进行恐吓、威胁、喝茶,甚至使用暴力。

72

10:31,643 --> 10:39,303
它的目的就是制造一种威慑效应,让大家明白有些红线是不能碰的,碰了是会有严重后果的。

73

10:39,833 --> 10:42,883
要让这种恐惧起作用,得满足什么条件呢?

74

10:43,453 --> 10:59,383
嗯,书里认为主要有两个条件。第一,人们得意识到这个后果的存在,知道说了或做了某些事可能会被惩罚。第二,人们得相信这个后果是会被执行的,就是说这个威胁必须是可信的(credible)。

75

11:00,130 --> 11:11,543
这就要求这种惩罚,或者至少是惩罚的威胁,必须是可见的,至少要让目标群体能够看到或者听说,“杀鸡儆猴”嘛,得让人看见。

76

11:12,123 --> 11:17,503
但我们前面刚讨论过“独裁者的困境”,这种可见性不就是一把双刃剑吗?

77

11:17,863 --> 11:39,263
完全正确,这正是基于恐惧的审查方式的主要弊端,他的可见性恰恰容易暴露政府压制信息的意图,引发反感和逆反心理,而且如果威胁喊得很响,但实际上执行不利,或者选择性执行,那反而会暴露政府的虚弱,让威胁变得不可信。

78

11:39,713 --> 11:55,273
嗯,尤其在互联网时代,人人有麦克风,网民数量极其庞大,你想通过制造恐惧来对数以亿计的普通网民进行普遍的、可信的威慑,那个成本高到无法想象,基本上是不可能完成的任务。

79

11:55,703 --> 11:56,873
所以书里的判断是,

80

11:57,213 --> 12:23,983
所以书中断言,在现代中国,这种基于恐惧的审查方式,更多的是被用来进行有针对性的威慑,目标主要是少数关键人物,比如媒体精英、人权活动家、知识分子、网络大V这些意见领袖,通过惩罚这些人来达到震慑其他类似群体的效果,但是对于广大的普通网民,普遍使用恐惧策略,既不现实,效果也可能适得其反。

81

12:24,403 --> 12:37,553
书中第四章甚至通过对微博用户的研究发现,普通用户在经历帖子被删这种审查之后,更多表现出来的是愤怒(anger),而不是恐惧(fear), 有些人甚至会因此更执着的去讨论那个被审查的话题。

82

12:38,063 --> 12:50,913
有意思,也就是说对大多数普通人,可能恐惧这个机制用的相对少了,或者说效果没那么好,那接下来这个“摩擦”可能就更重要了。

83

12:51,263 --> 13:05,103
这个概念对我来说就比较新颖,它不像恐惧那样直接用大棒威胁,听起来是让获取或者传播信息的过程变得不那么顺畅,像是在路上设置障碍。

84

13:05,533 --> 13:13,223
对,这个比喻非常形象,摩擦机制它直接作用于信息的可及性(accessibility)。

85

13:13,673 --> 13:35,463
他不是禁止你获取,而是增加你获取的难度和成本,就像是在信息高速公路上给你设置各种各样的障碍,可能是收费站,需要付费或付出努力；可能是减速带,让速度变慢；可能是绕路指示,让你花更多时间；甚至干脆把一些路标给你模糊掉。

86

13:35,933 --> 13:37,333
那具体有哪些形式呢?

87

13:37,703 --> 13:52,473
例子很多,可以从不同层面看,在网络层面最典型的就是防火墙(GFW),它屏蔽了大量的境外网站,像Google、Facebook、Twitter、纽约时报、YouTube这些,在中国大陆你直接是访问不了的。

88

13:52,473 --> 13:53,443
嗯,得用VPN。

89

13:53,683 --> 14:03,433
对,使用VPN本身就需要一定的技术门槛,有时需要付费,而且连接也可能不稳定,这就增加了时间和精力成本。

90

14:03,803 --> 14:15,133
还有一种是网站访问被限速(throttling),就是故意让你访问某个网站变得特别慢,让你觉得这个网站不好用,自己就放弃了,据说早期对Google就用过这招。

91

14:15,533 --> 14:16,063
嗯。

92

14:16,403 --> 14:25,243
在内容层面呢,比如说搜索引擎,它可能会过滤掉一些敏感的搜索结果,或者把他们排到非常非常后面,让你很难找到。

93

14:25,723 --> 14:28,473
这个确实,一般人也就看前两页搜索结果。

94

14:28,783 --> 14:38,723
是吧,还有社交媒体平台会删帖子或者屏蔽特定的关键词,你发的东西别人看不到,或者你搜某个词搜不到东西,这也是一种摩擦。

95

14:38,983 --> 14:39,523
嗯。

96

14:39,943 --> 14:53,193
传统媒体也有类似做法,比如监管机构可能会要求把一些敏感的报道放在报纸的次要版面,或者放在那个折叠线以下,就是你不把报纸展开就看不到的地方。

97

14:53,523 --> 14:55,243
都是为了降低信息的曝光度。

98

14:55,243 --> 14:56,093
对。

99

14:56,433 --> 15:15,363
甚至在数据获得层面也有,比如政府机构可能选择不去收集某些敏感的数据,或者收集了,但不公开,书里提到早期北京对PM2.5数据的处理,还有像美国关于警察枪击的数据其实也并不完整和统一。

100

15:16,023 --> 15:29,183
或者对于信息公开的请求,比如美国的FOIA(信息自由法案)请求,设置很高的费用或者故意拖延处理时间,这也是增加你获取信息的摩擦。

101

15:29,743 --> 15:50,563
我觉得这种摩擦策略,它最高明或者说最阴险的地方在于它往往很难被察觉,你可能就是觉得今天网速有点慢,或者这个关键词搜不到什么有用信息,你很难直接意识到这背后是有人在故意设置障碍,是审查行为。

102

15:50,913 --> 15:58,263
没错,这大大降低了引发公众不满和反弹的风险,不像恐惧那么容易激起对抗。

103

15:58,483 --> 15:58,843
嗯。

104

15:59,483 --> 16:17,533
而且我们前面不是说了“理性忽视”吗,大部分人对获取信息的那一点点不方便是很敏感的,只要稍微麻烦一点,很多人可能就算了,然后就去看点别的,更容易获得、更娱乐化的信息去了,他们的注意力就被成功转移了。

105

16:18,053 --> 16:25,603
所以即使是很小的摩擦,也能有效的阻止大多数人去接触那些需要费点劲才能得到的信息。

106

16:25,973 --> 16:26,813
正是如此。

107

16:27,333 --> 16:35,533
所以罗伯茨认为,摩擦在数字时代是一种非常有效,而且相对来说政治风险也比较低的审查策略。

108

16:35,933 --> 17:19,533
书中第五章通过调查数据和分析中国的推特用户(也就是翻墙用户),发现那些能够并且愿意经常翻墙的人,在中国网民里其实只占很小一部分,他们通常有一些共同特征,比如更年轻,教育程度更高,收入更高,可能有更多的海外联系,并且对政治更感兴趣,但同时他们对政府的信任度也相对较低,所以你看防火墙这样的摩擦机制,实际上在很大程度上是在没有引起大规模反弹的情况下,把这个相对精英的、信息需求和能力都比较高的小群体,与广大的普通网民在信息环境上进行了一种事实上的区隔。

109

17:20,033 --> 17:28,153
这个分析很有意思,等于说他容忍少数人翻墙,但通过摩擦把大多数人留在了墙内。

110

17:28,483 --> 17:31,433
可以这么理解,他实现了差异化的信息控制。

111

17:31,893 --> 17:39,333
书里还用了一些案例,比如谷歌退出中国大陆市场,维基百科和Instagram后来也被封锁,来说明摩擦的效果。

112

17:39,943 --> 17:46,233
对,他分析了这些服务被屏蔽前后用户行为和信息环境的变化。

113

17:46,653 --> 18:04,503
但他也指出,摩擦并非万无一失,比如说在发生重大突发公共事件,像书里提到的天津港爆炸案之后,公众对相关信息的需求会急剧上升,这时候人们克服摩擦的意愿就会大大增加。

114

18:05,023 --> 18:08,023
那时候VPN的下载量可能会暴增,是吧?

115

18:08,303 --> 18:18,923
对,书中提到了这个现象,危机事件会暂时性的降低人们对摩擦成本的敏感度,这时候审查系统就会面临更大的压力。

116

18:19,413 --> 18:32,243
好,理解了摩擦是通过增加难度来转移注意力,那最后一种机制,信息泛滥(flooding),这又是一种什么样的玩法呢?听起来像是信息太多了。

117

18:32,693 --> 19:02,683
嗯,如果说摩擦是在信息高速公路上设置障碍,那么泛滥就是反其道而行之,它是主动出击,向这条高速公路上倾倒大量的,可以说是垃圾信息,或者至少是无关的,或者是官方认可的信息,目的呢就是用这些海量的信息把你真正想找的那个敏感信息给淹没掉,就像是在信息海洋里故意制造大量的噪音,让你听不清你想听的声音。

118

19:03,113 --> 19:06,493
用大量信息来稀释或者掩盖特定信息。

119

19:06,943 --> 19:10,503
对,或者就是纯粹的分散你的注意力。

120

19:10,913 --> 19:39,123
主要有两种操作方式,第一种是直接面向公众进行灌水,政府或者他雇佣组织的代理人,比如说我们常听到的“五毛党”,或者说网络评论员,在社交媒体上大量的发布一些分散注意力的内容,这些内容可能跟敏感事件完全无关,比如发一些娱乐八卦呀,生活小窍门啊,或者就是一些正能量口号、爱国主义宣传等等。

121

19:39,473 --> 19:55,933
书里第六章重点分析了泄露出来的,据称是网评员的内部邮件和指令,发现他们接到的很多任务是发帖赞美政府的成就,或者在特定节日宣传主旋律,而不是直接去跟批评政府的人进行辩论。

122

19:56,033 --> 19:59,383
嗯,就是用看似无害的内容占领信息空间。

123

19:59,623 --> 20:17,623
对,而且这些帖子的发布时机往往跟一些敏感事件或者可能引发群体性讨论的事件高度相关,比如书里提到新疆发生骚乱,或者乌鲁木齐发生爆炸案之后,这类灌水帖就会大量出现,目的显然是为了转移公众视线。

124

20:18,053 --> 20:34,223
还有一个例子,像当年郭美美事件引发对红十字会的质疑时,正好发生云南地震,然后官方媒体就突然开始大规模的报道郭美美的其他八卦新闻,这也被认为是典型的用泛滥信息来分散注意力的案例。

125

20:34,703 --> 20:36,493
除了这种直接灌水还有其他方式吗?

126

20:37,023 --> 20:43,303
还有一种是通过影响传统媒体和内容生产者来实现泛滥。

127

20:43,923 --> 21:00,543
比如说,政府部门可以主动向媒体提供大量预先打包好的新闻稿、视频素材,这些素材都是符合官方口径的,媒体采用这些现成素材的成本很低,比自己去独立调查采访要省事的多。

128

21:00,773 --> 21:04,913
嗯,这等于是降低了传播官方信息的摩擦。

129

21:05,373 --> 21:16,133
没错,这样一来,官方版本的信息就更容易、更广泛的被传播,从而挤占了其他可能存在的不同声音或者独立报道的空间。

130

21:16,513 --> 21:38,423
还有一种更间接的,比如资助一些研究机构进行所谓的“平衡性研究”,得出一些对政府或者某些行业有利的结论,然后大力宣传这些研究结果,比如以前烟草公司就资助过研究来否认吸烟的危害,也是一种信息泛滥,试图混淆视听。

131

21:38,623 --> 21:49,533
这种泛滥策略,听起来它优势在于成本可能相对较低,尤其在数字时代,制造和传播大量信息好像挺便宜的。

132

21:49,913 --> 21:58,953
是的,相比于建立和维护像防火墙那样的摩擦系统,或者实施大规模恐惧威慑,信息泛滥的成本可能要低得多。

133

21:59,483 --> 22:15,483
而且它同样非常隐蔽,大量的正能量帖子,官方通告或者某些研究报告,表面上看起来可能像是自发的民意或者是正常的媒体报道,你很难直接把它定性为审查或者操纵。

134

22:15,813 --> 22:19,973
对,就这使得它引发的反感和抵触情绪也相对较小。

135

22:20,403 --> 22:27,533
书里还提到,这种策略在进行跨境信息影响,比如影响其他国家舆论的时候也特别有用。

136

22:27,993 --> 22:32,233
那书里有什么证据来证明这种泛滥策略是有效的吗?

137

22:32,563 --> 22:58,183
嗯,书中第六章做了一些很有意思的分析,比如他们分析了中国报纸文章的协调性,就是看有多少不同的报纸会在同一天刊登关于同一主题的内容相同或者高度相似的文章,他们发现这种协同发文的现象在一些政治敏感时期,比如重大会议期间或者发生某些政治丑闻之后会显著增加。

138

22:58,633 --> 23:01,173
这说明背后有统一的指令或者引导。

139

23:01,543 --> 23:16,003
很可能。而且他们还发现这些高度协调的内容,往往能在网络上获得更广泛的二次传播,这间接说明通过媒体进行的这种泛滥或者说议程设置是能够有效影响信息环境的。

140

23:16,403 --> 23:29,483
作者还分析了一个例子,就是在清明节期间,网络上关于革命烈士的讨论量会显著增加,他认为这可能也反映了官方试图通过信息泛滥来主导和重塑关于这个节日的公共叙事。

141

23:29,883 --> 23:33,403
用官方叙事来淹没其他可能的声音。

142

23:33,703 --> 23:45,413
对,用大量的看似正面或者中性的信息来占据人们有限的注意力,从而达到引导舆论或者至少是稀释、边缘化其他叙事的目的。

143

23:45,953 --> 24:10,653
好了,我们现在详细了解了这本书里提出的三种主要的审查机制：制造威慑的恐惧,增加麻烦的摩擦,还有用海量信息淹没你的泛滥。理解了这些理论和他们运作的方式之后,这对我们理解当今的信息环境有什么更深层次的启发呢?或者说,这一切对你来说意味着什么?

144

24:10,873 --> 24:19,253
嗯,我觉得这本书最大的贡献,或者说它的主要启发在于它挑战了一些我们关于信息和审查的传统看法。

145

24:19,653 --> 24:26,103
首先,他告诉我们在信息时代,审查并没有像一些人预测的那样失效或者过时。

146

24:26,503 --> 24:42,913
审查依然存在,而且可能变得更加定制化,审查策略会根据不同人群的特点,比如你的动机强不强,你的技术能力怎么样,产生不同的效果,而且政府会很策略性的去利用这种人群之间的差异。

147

24:42,913 --> 24:44,353
嗯,不是一刀切了。

148

24:44,353 --> 24:44,793
对。

149

24:45,193 --> 25:13,223
其次,这本书深刻的揭示了,即使在一个信息看起来好像自由流动的环境里,信息的可及性,也就是你获取信息的方便程度,本身就具有巨大的政治影响力,你不需要完全封锁一个信息,你只要让它变得稍微难获取一点点,或者用大量的噪音把它淹没掉,就足以对公众的认识、态度甚至行为产生非常深远的影响,这种控制往往是发生在潜移默化之中的,不容易被察觉。

150

25:13,633 --> 25:26,303
而且就像书的结尾部分也提到的,这种对摩擦和泛滥机制的理解,它的意义其实不局限于威权国家,对我们生活在所谓民主社会的人来说,同样具有警示意义。

151

25:26,623 --> 25:48,273
的确如此,这本书虽然主要以中国为案例,但他提出的分析框架是有普遍性的,比如说在西方国家,少数大型科技公司,他们通过搜索引擎的算法,社交媒体的信息流推荐,实际上就在很大程度上决定了我们能看到什么信息,不能看到什么信息,这本身算不算一种无形的摩擦和泛滥?

152

25:48,633 --> 25:49,343
这是个好问题。

153

25:49,703 --> 26:22,483
对吧,还有互联网服务提供商如果搞所谓的“快车道、慢车道”,对不同的网络内容区别对待,这也是一种摩擦,政府机构在数据公开方面是不是也存在选择性的透明,有些数据公开的很及时,有些就很难拿到,也是摩擦,再加上现在网络上各种水军、虚假信息、宣传机器的泛滥,这些都可能在没有采取强制性恐惧手段的情况下,深刻的塑造公众舆论,影响我们的政治生态。

154

26:22,643 --> 26:26,533
嗯,这些确实都是我们身边可能正在发生的事情。

155

26:26,873 --> 26:43,263
所以,这本书就提出了一个非常重要也非常严肃的问题,在一个信息似乎唾手可得,但我们的注意力却成为最稀缺资源的时代,我们到底应该如何来界定和保护珍贵的言论自由和知情权,仅仅没有恐惧就够了吗?

156

26:43,623 --> 26:56,033
这本书确实为我们理解信息控制提供了一个非常精细也很有力的分析框架。他提醒我们,对信息的控制,其形式远比我们过去想象的要多得多,可能也隐蔽得多。

157

26:56,663 --> 26:58,423
不仅是删除和封锁那么简单。

158

26:58,883 --> 26:59,383
是的。

159

26:59,683 --> 27:13,103
他促使我们思考,当我们观察我们周围的信息环境时,或许我们不仅要关注那些被明确禁止的声音,也要留意那些被优先推送的声音,以及那些被各种噪音巧妙淹没的声音。

160

27:13,543 --> 27:31,343
这就自然引出了一个我觉得值得你继续思考的问题：在一个信息过载,注意力极其宝贵的时代,真正的自由地获取信息到底意味着什么?面对那些越来越难以察觉的信息摩擦和泛滥,我们又该如何保持清醒的头脑和批判性的辨别力呢? 

161

27:31,693 --> 27:31,983
嗯。

162

27:32,303 --> 27:42,493
这确实是留给我们所有人的一个重要课题。非常感谢你今天和我们一起如此深入的探讨了玛格丽特·罗伯茨的《审查》这本书的核心内容。

163

27:42,883 --> 27:49,153
希望这次讨论能帮助你更好的理解我们当下所处的这个复杂而重要的信息世界。

164

27:49,553 --> 27:51,753
谢谢收听,下期节目再见。

165

27:52,193 --> 27:53,043
